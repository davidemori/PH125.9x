---
title: "Movielens Project"
author: "Davide Mori"
date: "30/9/2019"
output: html_document
toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```
# PH125.9X - Capstone

## R Background
A recommender system or a recommendation system (sometimes replacing 'system' with a synonym such as platform or engine) is a subclass of information filtering system that seeks to predict the "rating" or "preference" a user would give to an item.They are primarily used in commercial applications.Recommender systems are utilized in a variety of areas, and are most commonly recognized as playlist generators for video and music services like Netflix, YouTube and Spotify, product recommenders for services such as Amazon, or content recommenders for social media platforms such as Facebook and Twitter. These systems can operate using a single input, like music, or multiple inputs within and across platforms like news, books, and search queries. There are also popular recommender systems for specific topics like restaurants and online dating. Recommender systems have been developed to explore research articles and experts,collaborators, financial services, and life insurance. [Wikipedia, 2019]

## Goal of the project
The aim for this project is find a machine learning algorithm that can predicts user ratings (from 0.5 to 5 stars). For this project we will have to use an edx train subset of complete movielens dataset, and a validation set to verify our results.
The evaluation criteria for this algorithm is a RMSE expected to be lower than 0.8775.
The function that computes the RMSE for vectors of ratings and their corresponding predictors will be the following:
$$ RMSE = \sqrt{\frac{1}{N}\displaystyle\sum_{u,i} (\hat{y}_{u,i}-y_{u,i})^{2}} $$

```{r RMSE_function1, echo = FALSE}
RMSE <- function(predicted_ratings, true_ratings){
  sqrt(mean((predicted_ratings - true_ratings)^2))
}
```

The best resulting algorithm will be used to predict the movie ratings.

## Introduction to dataset

The dataset is loaded from edx with the following given code:

################################
```{r, echo = TRUE, message = FALSE, warning = FALSE, eval = TRUE}
# Create edx set, validation set
################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data

set.seed(1, sample.kind="Rounding")
# if using R 3.5 or earlier, use `set.seed(1)` instead
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set

validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set

removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```


# Methods and Analyses


## Data Exploration Analysis

To get familiar with the dataset, we find the first 10 rows of "edx" subset as below.
The subset contain the six variables “userID”, “movieID”, “rating”, “timestamp”, “title”, and “genres”. Each row represent a single rating of a user for a single movie.

```{r, echo = FALSE}
head(edx, 10) %>% 
  knitr::kable()
```

We also provided a summary of the subset, that confirms the absence of missing values.

```{r summary, echo = FALSE}
summary(edx)
```

As shown The total of unique movies in the edx subset are about 10677 different movies and there are about 70.000 unique users:

```{r, echo = FALSE}
edx %>%
  summarize(n_users = n_distinct(userId), 
            n_movies = n_distinct(movieId),
            n_ratings_entries = n(),
            n_rating_levels = n_distinct(rating))

```

Users have a preference to rate movies rather higher than lower as shown by the distribution of ratings below. 4 is the most common rating, followed by 3 and 5. 0.5 is the least common rating. In general, half rating are less common than whole star ratings.

```{r rating_distribution, echo = FALSE}
edx %>%
  ggplot(aes(rating)) +
  geom_histogram(binwidth = 0.5, color = "black", fill="rosybrown") +
  scale_x_discrete(limits = c(seq(0.5,5,0.5))) +
  scale_y_continuous(breaks = c(seq(0, 3000000, 250000))) +
  ggtitle("Ratings distribution")
  
```

After further analyses we can observe that some movies have been rated much often than other, while some have very few ratings. This will be important for our model and for our further model in terms of regularization.
Regularizations are techniques used to reduce the error by fitting a function appropriately on the given training set and avoid overfitting (the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably). Regularization is a technique used for tuning the function by adding an additional penalty term in the error function. The additional term controls the excessively fluctuating function such that the coefficients don’t take extreme values.


```{r number_of_ratings_per_movie, echo = TRUE, fig.height=4, fig.width=5}
edx %>%
  count(movieId) %>%
  ggplot(aes(n)) +
  geom_histogram(bins = 30, color = "black", fill="rosybrown") +
  scale_x_log10() +
  xlab("Number of ratings") +
  ylab("Number of movies") +
  ggtitle("Number of ratings per movie")
```

Here we show the movies with only one rating score.

```{r number_of_ratings_per_movie, echo = TRUE, fig.height=4, fig.width=5}
edx %>%
  group_by(movieId) %>%
  summarize(count = n()) %>%
  filter(count == 1) %>%
  left_join(edx, by = "movieId") %>%
  group_by(title) %>%
  summarize(rating = rating, n_rating = count) %>%
  slice(1:25) %>%
  knitr::kable()
```

As we can observe, the majority of users have rated a number of movies between 30 and 100. So, also a user penalty term need to be included later in our models.


```{r number_ratings_given_by_users, echo = TRUE, fig.height=4, fig.width=5}
edx %>%
count(userId) %>%
ggplot(aes(n)) +
geom_histogram(bins = 30, color = "black", fill = "rosybrown") +
scale_x_log10() +
xlab("Number of ratings") + 
ylab("Number of users") +
ggtitle("Number of ratings given by users")
```

Furthermore, users differ vastly in how critical they are with their ratings. Some users tend to give much lower star ratings and some users tend to give higher star ratings than average.


```{r Mean_movie_ratings_given_by_users, echo = TRUE, fig.height=4, fig.width=5}
edx %>%
  group_by(userId) %>%
  filter(n() >= 100) %>%
  summarize(b_u = mean(rating)) %>%
  ggplot(aes(b_u)) +
  geom_histogram(bins = 30, color = "black", fill="rosybrown") +
  xlab("Mean rating") +
  ylab("Number of users") +
  ggtitle("Mean movie ratings given by users") +
  scale_x_discrete(limits = c(seq(0.5,5,0.5))) +
  theme_light()
  
```

## Modelling Approach

We write now the loss-function, previously anticipated, that compute the RMSE, defined as follows:

$$ RMSE = \sqrt{\frac{1}{N}\displaystyle\sum_{u,i} (\hat{y}_{u,i}-y_{u,i})^{2}} $$


with N being the number of user/movie combinations and the sum occurring over all these combinations.
The RMSE is our measure of model accuracy.
We can interpret the RMSE similarly to a standard deviation: it is the typical error we make when predicting a movie rating. If its result is larger than 1, it means that our typical error is larger than one star, which is not a good result.
The written function to compute the RMSE for vectors of ratings and their corresponding predictions is:


```{r RMSE_function2, echo = TRUE}
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
```

The lower the better, as said previously.




